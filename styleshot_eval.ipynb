{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.nn.functional import mse_loss\n",
    "from scipy.linalg import sqrtm\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_best(data):\n",
    "    color = 'green'\n",
    "    attr = f'background-color: {color}'\n",
    "    \n",
    "    if data.ndim == 1:  # Single row or column (Series)\n",
    "        # Highlight based on whether the metric prefers min or max\n",
    "        if 'Loss' in data.name or 'FID' in data.name:\n",
    "            is_best = data == data.min()  # For Loss or FID, lower is better\n",
    "        else:\n",
    "            is_best = data == data.max()  # For Similarity, higher is better\n",
    "        return [attr if v else '' for v in is_best]\n",
    "    else:  # DataFrame case\n",
    "        styled_df = pd.DataFrame('', index=data.index, columns=data.columns)\n",
    "        for col in data.columns:\n",
    "            if 'Loss' in col or 'FID' in col:\n",
    "                is_best = data[col] == data[col].min()  # Min for Loss and FID\n",
    "            else:\n",
    "                is_best = data[col] == data[col].max()  # Max for Similarity\n",
    "            styled_df.loc[is_best, col] = attr\n",
    "        return styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f0688_row0_col4, #T_f0688_row0_col5, #T_f0688_row3_col1, #T_f0688_row3_col2, #T_f0688_row3_col3 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f0688\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f0688_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
       "      <th id=\"T_f0688_level0_col1\" class=\"col_heading level0 col1\" >Content Loss↓</th>\n",
       "      <th id=\"T_f0688_level0_col2\" class=\"col_heading level0 col2\" >Content Similarity↑</th>\n",
       "      <th id=\"T_f0688_level0_col3\" class=\"col_heading level0 col3\" >Style Loss↓</th>\n",
       "      <th id=\"T_f0688_level0_col4\" class=\"col_heading level0 col4\" >Style Similarity↑</th>\n",
       "      <th id=\"T_f0688_level0_col5\" class=\"col_heading level0 col5\" >FID↓</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f0688_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f0688_row0_col0\" class=\"data row0 col0\" >original</td>\n",
       "      <td id=\"T_f0688_row0_col1\" class=\"data row0 col1\" >13.881 ±2.268</td>\n",
       "      <td id=\"T_f0688_row0_col2\" class=\"data row0 col2\" >0.257 ±0.032</td>\n",
       "      <td id=\"T_f0688_row0_col3\" class=\"data row0 col3\" >0.022 ±0.012</td>\n",
       "      <td id=\"T_f0688_row0_col4\" class=\"data row0 col4\" >0.469 ±0.052</td>\n",
       "      <td id=\"T_f0688_row0_col5\" class=\"data row0 col5\" >12.685 ±5.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0688_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f0688_row1_col0\" class=\"data row1 col0\" >lab</td>\n",
       "      <td id=\"T_f0688_row1_col1\" class=\"data row1 col1\" >13.192 ±1.907</td>\n",
       "      <td id=\"T_f0688_row1_col2\" class=\"data row1 col2\" >0.273 ±0.033</td>\n",
       "      <td id=\"T_f0688_row1_col3\" class=\"data row1 col3\" >0.025 ±0.014</td>\n",
       "      <td id=\"T_f0688_row1_col4\" class=\"data row1 col4\" >0.448 ±0.044</td>\n",
       "      <td id=\"T_f0688_row1_col5\" class=\"data row1 col5\" >20.539 ±8.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0688_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f0688_row2_col0\" class=\"data row2 col0\" >luv</td>\n",
       "      <td id=\"T_f0688_row2_col1\" class=\"data row2 col1\" >13.355 ±1.831</td>\n",
       "      <td id=\"T_f0688_row2_col2\" class=\"data row2 col2\" >0.274 ±0.031</td>\n",
       "      <td id=\"T_f0688_row2_col3\" class=\"data row2 col3\" >0.024 ±0.013</td>\n",
       "      <td id=\"T_f0688_row2_col4\" class=\"data row2 col4\" >0.447 ±0.044</td>\n",
       "      <td id=\"T_f0688_row2_col5\" class=\"data row2 col5\" >19.718 ±6.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0688_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f0688_row3_col0\" class=\"data row3 col0\" >pca</td>\n",
       "      <td id=\"T_f0688_row3_col1\" class=\"data row3 col1\" >13.178 ±2.021</td>\n",
       "      <td id=\"T_f0688_row3_col2\" class=\"data row3 col2\" >0.278 ±0.026</td>\n",
       "      <td id=\"T_f0688_row3_col3\" class=\"data row3 col3\" >0.021 ±0.011</td>\n",
       "      <td id=\"T_f0688_row3_col4\" class=\"data row3 col4\" >0.448 ±0.043</td>\n",
       "      <td id=\"T_f0688_row3_col5\" class=\"data row3 col5\" >19.159 ±5.958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7d6f454d3d60>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = \"evaluation/evaluation.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "metrics = df.columns[1:]\n",
    "df.style.apply(highlight_best, subset=metrics, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_eval_images(group_id, methods):\n",
    "    content_dir = f'data/Content/content{group_id}'\n",
    "    style_dir = f'data/Style/style{group_id}'\n",
    "    stylized_dir = f'output/before_styleshot/style{group_id}_content{group_id}'\n",
    "\n",
    "    content_out = f'evaluation/Content/content{group_id}'\n",
    "    style_out = f'evaluation/Style/style{group_id}'\n",
    "\n",
    "    os.makedirs(content_out, exist_ok=True)\n",
    "    os.makedirs(style_out, exist_ok=True)\n",
    "\n",
    "    content_files = sorted(os.listdir(content_dir))\n",
    "    style_files = sorted(os.listdir(style_dir))\n",
    "    for method in methods:\n",
    "        stylized_out = f'evaluation/Stylized/style{group_id}_content{group_id}/{method}'\n",
    "        os.makedirs(stylized_out, exist_ok=True)\n",
    "\n",
    "        for style_file in tqdm(style_files, desc=f'Processing styles for method {method}'):\n",
    "            for content_file in tqdm(content_files, desc=f'Processing contents for style {style_file}', leave=False):\n",
    "                content = Image.open(os.path.join(content_dir, content_file)).resize((256, 256))\n",
    "                style = Image.open(os.path.join(style_dir, style_file)).resize((256, 256))\n",
    "\n",
    "                content_number = int(content_file.split('.')[0])\n",
    "                style_number = int(style_file.split('.')[0])\n",
    "                stylized_path = f\"{stylized_dir}/{style_number:02d}_{content_number:02d}_{method}_styleshot.png\"\n",
    "                if not os.path.exists(stylized_path):\n",
    "                    continue\n",
    "                \n",
    "                stylized = Image.open(f\"{stylized_dir}/{style_number:02d}_{content_number:02d}_{method}_styleshot.png\").resize((256, 256))\n",
    "\n",
    "                content.save(os.path.join(content_out, f'{style_number:02d}_{content_number:02d}.png'))\n",
    "                style.save(os.path.join(style_out, f'{style_number:02d}_{content_number:02d}.png'))\n",
    "                stylized.save(os.path.join(stylized_out, f'{style_number:02d}_{content_number:02d}.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG19Extractor(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG19Extractor, self).__init__()\n",
    "        vgg = models.vgg19(weights='VGG19_Weights.DEFAULT').features.eval()\n",
    "        self.layers = {\n",
    "            '0': 'conv1_1',  # Style layer\n",
    "            '5': 'conv2_1',  # Style layer\n",
    "            '10': 'conv3_1', # Style layer\n",
    "            '19': 'conv4_1', # Style layer\n",
    "            '21': 'conv4_2', # Content layer\n",
    "            '28': 'conv5_1'  # Style layer\n",
    "        }\n",
    "        self.model = torch.nn.Sequential(*list(vgg)[:29])  # 裁剪模型\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = {}\n",
    "        for name, layer in self.model._modules.items():\n",
    "            x = layer(x)\n",
    "            if name in self.layers:\n",
    "                features[self.layers[name]] = x\n",
    "        return features\n",
    "\n",
    "class VGG16Extractor(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16Extractor, self).__init__()\n",
    "        vgg = models.vgg16(weights='VGG16_Weights.DEFAULT').features.eval()\n",
    "        self.layers = {\n",
    "            '0': 'conv1_1',  # Style layer\n",
    "            '5': 'conv2_1',  # Style layer\n",
    "            '10': 'conv3_1', # Style layer\n",
    "            '17': 'conv4_1', # Style layer\n",
    "            '19': 'conv4_2', # Content layer\n",
    "            '24': 'conv5_1'  # Style layer\n",
    "        }\n",
    "        self.model = torch.nn.Sequential(*list(vgg)[:29])  # 裁剪模型\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = {}\n",
    "        for name, layer in self.model._modules.items():\n",
    "            x = layer(x)\n",
    "            if name in self.layers:\n",
    "                features[self.layers[name]] = x\n",
    "        return features\n",
    "\n",
    "def gram_matrix(tensor):\n",
    "    b, c, h, w = tensor.size()\n",
    "    features = tensor.view(b, c, h * w)\n",
    "    gram = torch.bmm(features, features.transpose(1, 2))\n",
    "    return gram\n",
    "\n",
    "def calculate_fid(mean1, cov1, mean2, cov2):\n",
    "    diff = np.sum((mean1 - mean2) ** 2)\n",
    "    cov_mean = sqrtm(np.dot(cov1, cov2))\n",
    "    if np.iscomplexobj(cov_mean):\n",
    "        cov_mean = cov_mean.real  # 去掉複數部分\n",
    "    fid = diff + np.trace(cov1 + cov2 - 2 * cov_mean)\n",
    "    return fid\n",
    "\n",
    "def preprocess_images(image_paths):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        images.append(transform(image).unsqueeze(0))\n",
    "    return torch.cat(images, dim=0).cuda()\n",
    "\n",
    "def extract_features_and_calculate_metrics(content_images, style_images, stylized_images, model, batch_size=1):\n",
    "    num_samples = content_images.size(0)\n",
    "    content_loss = 0.0\n",
    "    content_similarity = 0.0\n",
    "    style_loss_gram = 0.0\n",
    "    style_loss_similarity = 0.0\n",
    "    style_features_list = []\n",
    "    stylized_features_list = []\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        content_batch = content_images[i:i+batch_size]\n",
    "        style_batch = style_images[i:i+batch_size]\n",
    "        stylized_batch = stylized_images[i:i+batch_size]\n",
    "        gray_style_batch = transforms.Grayscale()(style_batch)\n",
    "        gray_style_batch = gray_style_batch.repeat(1, 3, 1, 1)\n",
    "        gray_stylized_batch = transforms.Grayscale()(stylized_batch)\n",
    "        gray_stylized_batch = gray_stylized_batch.repeat(1, 3, 1, 1)\n",
    "\n",
    "        # 提取特徵\n",
    "        content_features = model(content_batch)\n",
    "        # style_features = model(style_batch)\n",
    "        stylized_features = model(stylized_batch)\n",
    "        gray_style_features = model(gray_style_batch)\n",
    "        gray_stylized_features = model(gray_stylized_batch)\n",
    "\n",
    "        # 累加內容損失\n",
    "        content_loss += mse_loss(stylized_features['conv4_2'], content_features['conv4_2']).item()\n",
    "        # content_loss += torch.norm(stylized_features['conv4_2'] - content_features['conv4_2'], p=2).item()\n",
    "        content_similarity += torch.nn.functional.cosine_similarity(stylized_features['conv4_2'], content_features['conv4_2'], dim=1).mean().item()\n",
    "        style_loss_similarity += torch.nn.functional.cosine_similarity(gray_stylized_features['conv2_1'], gray_style_features['conv2_1'], dim=1).mean().item()\n",
    "        \n",
    "        # 累加風格損失\n",
    "        style_weights = {'conv1_1': 1.,\n",
    "                 'conv2_1': 0.75,\n",
    "                 'conv3_1': 0.2,\n",
    "                 'conv4_1': 0.2,\n",
    "                 'conv5_1': 0.2}\n",
    "        for layer in ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']:\n",
    "            gram_style = gram_matrix(gray_style_features[layer])\n",
    "            gram_stylized = gram_matrix(gray_stylized_features[layer])\n",
    "            b, c, h, w = gray_style_features[layer].size()\n",
    "            style_loss_gram += style_weights[layer] * torch.sum((gram_style - gram_stylized) ** 2) / (4 * (c ** 2) * (h * w) ** 2)\n",
    "\n",
    "        # 保存特徵供後續計算 FID\n",
    "        style_features_list.append(torch.flatten(gray_style_features['conv2_1'], start_dim=2).permute(0, 2, 1))\n",
    "        stylized_features_list.append(torch.flatten(gray_stylized_features['conv2_1'], start_dim=2).permute(0, 2, 1))\n",
    "\n",
    "    # 拼接所有批次的特徵\n",
    "    style_flattened = torch.cat(style_features_list, dim=0).reshape(-1, style_features_list[0].shape[-1]).detach().cpu().numpy()\n",
    "    stylized_flattened = torch.cat(stylized_features_list, dim=0).reshape(-1, stylized_features_list[0].shape[-1]).detach().cpu().numpy()\n",
    "\n",
    "    # 計算相似度\n",
    "    content_similarity /= (num_samples / batch_size)\n",
    "    style_loss_gram /= (num_samples / batch_size)\n",
    "    style_loss_similarity /= (num_samples / batch_size)\n",
    "    \n",
    "    # 計算 FID\n",
    "    mean_style = np.mean(style_flattened, axis=0)\n",
    "    mean_stylized = np.mean(stylized_flattened, axis=0)\n",
    "    cov_style = np.cov(style_flattened, rowvar=False)\n",
    "    cov_stylized = np.cov(stylized_flattened, rowvar=False)\n",
    "    fid = calculate_fid(mean_style, cov_style, mean_stylized, cov_stylized)\n",
    "\n",
    "    # 返回平均損失與 FID\n",
    "    content_loss /= (num_samples / batch_size)\n",
    "    style_loss_gram /= (num_samples / batch_size)\n",
    "    return content_loss, style_loss_gram, content_similarity, style_loss_similarity, fid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_methods(group_id, methods, vgg_extractor):\n",
    "    content_dir = f\"evaluation/Content/content{group_id}\"\n",
    "    style_dir = f\"evaluation/Style/style{group_id}\"\n",
    "    results = []\n",
    "    for method in methods:\n",
    "        stylized_dir = f\"evaluation/Stylized/style{group_id}_content{group_id}/{method}\"\n",
    "        \n",
    "        content_paths = [os.path.join(content_dir, file) for file in os.listdir(content_dir)]\n",
    "        style_paths = [os.path.join(style_dir, file) for file in os.listdir(style_dir)]\n",
    "        stylized_paths = [os.path.join(stylized_dir, file) for file in os.listdir(stylized_dir)]\n",
    "\n",
    "        # remove the image which does not have stylized image\n",
    "        content_paths = [path for path in content_paths if os.path.exists(os.path.join(stylized_dir, os.path.basename(path)))]\n",
    "        style_paths = [path for path in style_paths if os.path.exists(os.path.join(stylized_dir, os.path.basename(path)))]\n",
    "        stylized_paths = [path for path in stylized_paths if os.path.exists(path)]\n",
    "\n",
    "        assert len(stylized_paths) != 0\n",
    "        assert len(content_paths) == len(style_paths) == len(stylized_paths)\n",
    "\n",
    "        # preprocess images\n",
    "        content_images = preprocess_images(content_paths)\n",
    "        style_images = preprocess_images(style_paths)\n",
    "        stylized_images = preprocess_images(stylized_paths)\n",
    "        \n",
    "        # extract features and calculate metrics\n",
    "        vgg_extractor = vgg_extractor.cuda()\n",
    "        content_loss, style_loss, content_similarity, style_loss_similarity, fid_score = extract_features_and_calculate_metrics(content_images, style_images, stylized_images, vgg_extractor)\n",
    "\n",
    "        results.append({\n",
    "            \"Method\": method,\n",
    "            \"Content Loss↓\": content_loss,\n",
    "            \"Content Similarity↑\": content_similarity,\n",
    "            \"Style Loss↓\": style_loss.item(),\n",
    "            \"Style Similarity↑\": style_loss_similarity,\n",
    "            \"FID↓\": fid_score\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg_extractor = VGG19Extractor().eval()\n",
    "vgg_extractor = VGG16Extractor().eval()\n",
    "result_all = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id = \"1\"\n",
    "methods = [\"original\", \"lab\", \"luv\", \"pca\"]\n",
    "data_path = os.path.join('evaluation', 'Stylized', f'style{group_id}_content{group_id}')\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    prepare_eval_images(group_id, methods)\n",
    "\n",
    "result = evaluate_methods(group_id, methods, vgg_extractor)\n",
    "result_all.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bb908_row0_col1, #T_bb908_row0_col3, #T_bb908_row0_col4, #T_bb908_row0_col5, #T_bb908_row1_col2 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bb908\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bb908_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
       "      <th id=\"T_bb908_level0_col1\" class=\"col_heading level0 col1\" >Content Loss↓</th>\n",
       "      <th id=\"T_bb908_level0_col2\" class=\"col_heading level0 col2\" >Content Similarity↑</th>\n",
       "      <th id=\"T_bb908_level0_col3\" class=\"col_heading level0 col3\" >Style Loss↓</th>\n",
       "      <th id=\"T_bb908_level0_col4\" class=\"col_heading level0 col4\" >Style Similarity↑</th>\n",
       "      <th id=\"T_bb908_level0_col5\" class=\"col_heading level0 col5\" >FID↓</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bb908_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bb908_row0_col0\" class=\"data row0 col0\" >original</td>\n",
       "      <td id=\"T_bb908_row0_col1\" class=\"data row0 col1\" >12.309853</td>\n",
       "      <td id=\"T_bb908_row0_col2\" class=\"data row0 col2\" >0.311889</td>\n",
       "      <td id=\"T_bb908_row0_col3\" class=\"data row0 col3\" >0.008386</td>\n",
       "      <td id=\"T_bb908_row0_col4\" class=\"data row0 col4\" >0.528632</td>\n",
       "      <td id=\"T_bb908_row0_col5\" class=\"data row0 col5\" >5.826602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb908_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bb908_row1_col0\" class=\"data row1 col0\" >lab</td>\n",
       "      <td id=\"T_bb908_row1_col1\" class=\"data row1 col1\" >12.332293</td>\n",
       "      <td id=\"T_bb908_row1_col2\" class=\"data row1 col2\" >0.329475</td>\n",
       "      <td id=\"T_bb908_row1_col3\" class=\"data row1 col3\" >0.012314</td>\n",
       "      <td id=\"T_bb908_row1_col4\" class=\"data row1 col4\" >0.496788</td>\n",
       "      <td id=\"T_bb908_row1_col5\" class=\"data row1 col5\" >15.291359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb908_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_bb908_row2_col0\" class=\"data row2 col0\" >luv</td>\n",
       "      <td id=\"T_bb908_row2_col1\" class=\"data row2 col1\" >12.617935</td>\n",
       "      <td id=\"T_bb908_row2_col2\" class=\"data row2 col2\" >0.324316</td>\n",
       "      <td id=\"T_bb908_row2_col3\" class=\"data row2 col3\" >0.012947</td>\n",
       "      <td id=\"T_bb908_row2_col4\" class=\"data row2 col4\" >0.495013</td>\n",
       "      <td id=\"T_bb908_row2_col5\" class=\"data row2 col5\" >17.760267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb908_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_bb908_row3_col0\" class=\"data row3 col0\" >pca</td>\n",
       "      <td id=\"T_bb908_row3_col1\" class=\"data row3 col1\" >12.453870</td>\n",
       "      <td id=\"T_bb908_row3_col2\" class=\"data row3 col2\" >0.322147</td>\n",
       "      <td id=\"T_bb908_row3_col3\" class=\"data row3 col3\" >0.012017</td>\n",
       "      <td id=\"T_bb908_row3_col4\" class=\"data row3 col4\" >0.498604</td>\n",
       "      <td id=\"T_bb908_row3_col5\" class=\"data row3 col5\" >14.471770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7d6f454d3c40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(result)\n",
    "# save to csv\n",
    "df.to_csv(f\"evaluation/evaluation{group_id}.csv\", index=False)\n",
    "\n",
    "# show table\n",
    "df.style.apply(highlight_best, subset=['Content Loss↓', 'Content Similarity↑','Style Loss↓', 'Style Similarity↑', 'FID↓'], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id = \"2\"\n",
    "methods = [\"original\", \"lab\", \"luv\", \"pca\"]\n",
    "data_path = os.path.join('evaluation', 'Stylized', f'style{group_id}_content{group_id}')\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    prepare_eval_images(group_id, methods)\n",
    "\n",
    "result = evaluate_methods(group_id, methods, vgg_extractor)\n",
    "result_all.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_93f87_row0_col4, #T_93f87_row0_col5, #T_93f87_row3_col1, #T_93f87_row3_col2, #T_93f87_row3_col3 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_93f87\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_93f87_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
       "      <th id=\"T_93f87_level0_col1\" class=\"col_heading level0 col1\" >Content Loss↓</th>\n",
       "      <th id=\"T_93f87_level0_col2\" class=\"col_heading level0 col2\" >Content Similarity↑</th>\n",
       "      <th id=\"T_93f87_level0_col3\" class=\"col_heading level0 col3\" >Style Loss↓</th>\n",
       "      <th id=\"T_93f87_level0_col4\" class=\"col_heading level0 col4\" >Style Similarity↑</th>\n",
       "      <th id=\"T_93f87_level0_col5\" class=\"col_heading level0 col5\" >FID↓</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_93f87_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_93f87_row0_col0\" class=\"data row0 col0\" >original</td>\n",
       "      <td id=\"T_93f87_row0_col1\" class=\"data row0 col1\" >13.002435</td>\n",
       "      <td id=\"T_93f87_row0_col2\" class=\"data row0 col2\" >0.248395</td>\n",
       "      <td id=\"T_93f87_row0_col3\" class=\"data row0 col3\" >0.024121</td>\n",
       "      <td id=\"T_93f87_row0_col4\" class=\"data row0 col4\" >0.503800</td>\n",
       "      <td id=\"T_93f87_row0_col5\" class=\"data row0 col5\" >13.567996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93f87_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_93f87_row1_col0\" class=\"data row1 col0\" >lab</td>\n",
       "      <td id=\"T_93f87_row1_col1\" class=\"data row1 col1\" >12.587451</td>\n",
       "      <td id=\"T_93f87_row1_col2\" class=\"data row1 col2\" >0.260694</td>\n",
       "      <td id=\"T_93f87_row1_col3\" class=\"data row1 col3\" >0.038233</td>\n",
       "      <td id=\"T_93f87_row1_col4\" class=\"data row1 col4\" >0.469793</td>\n",
       "      <td id=\"T_93f87_row1_col5\" class=\"data row1 col5\" >30.600827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93f87_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_93f87_row2_col0\" class=\"data row2 col0\" >luv</td>\n",
       "      <td id=\"T_93f87_row2_col1\" class=\"data row2 col1\" >12.964930</td>\n",
       "      <td id=\"T_93f87_row2_col2\" class=\"data row2 col2\" >0.256767</td>\n",
       "      <td id=\"T_93f87_row2_col3\" class=\"data row2 col3\" >0.036225</td>\n",
       "      <td id=\"T_93f87_row2_col4\" class=\"data row2 col4\" >0.469322</td>\n",
       "      <td id=\"T_93f87_row2_col5\" class=\"data row2 col5\" >24.910811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_93f87_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_93f87_row3_col0\" class=\"data row3 col0\" >pca</td>\n",
       "      <td id=\"T_93f87_row3_col1\" class=\"data row3 col1\" >11.646391</td>\n",
       "      <td id=\"T_93f87_row3_col2\" class=\"data row3 col2\" >0.277837</td>\n",
       "      <td id=\"T_93f87_row3_col3\" class=\"data row3 col3\" >0.021411</td>\n",
       "      <td id=\"T_93f87_row3_col4\" class=\"data row3 col4\" >0.465101</td>\n",
       "      <td id=\"T_93f87_row3_col5\" class=\"data row3 col5\" >19.891932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7d6fe9c86520>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(result)\n",
    "# save to csv\n",
    "df.to_csv(f\"evaluation/evaluation{group_id}.csv\", index=False)\n",
    "\n",
    "# show table\n",
    "df.style.apply(highlight_best, subset=['Content Loss↓', 'Content Similarity↑','Style Loss↓', 'Style Similarity↑', 'FID↓'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id = \"3\"\n",
    "methods = [\"original\", \"lab\", \"luv\", \"pca\"]\n",
    "data_path = os.path.join('evaluation', 'Stylized', f'style{group_id}_content{group_id}')\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    prepare_eval_images(group_id, methods)\n",
    "\n",
    "result = evaluate_methods(group_id, methods, vgg_extractor)\n",
    "result_all.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4e11b_row0_col4, #T_4e11b_row0_col5, #T_4e11b_row1_col1, #T_4e11b_row1_col3, #T_4e11b_row3_col2 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4e11b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4e11b_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
       "      <th id=\"T_4e11b_level0_col1\" class=\"col_heading level0 col1\" >Content Loss↓</th>\n",
       "      <th id=\"T_4e11b_level0_col2\" class=\"col_heading level0 col2\" >Content Similarity↑</th>\n",
       "      <th id=\"T_4e11b_level0_col3\" class=\"col_heading level0 col3\" >Style Loss↓</th>\n",
       "      <th id=\"T_4e11b_level0_col4\" class=\"col_heading level0 col4\" >Style Similarity↑</th>\n",
       "      <th id=\"T_4e11b_level0_col5\" class=\"col_heading level0 col5\" >FID↓</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4e11b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4e11b_row0_col0\" class=\"data row0 col0\" >original</td>\n",
       "      <td id=\"T_4e11b_row0_col1\" class=\"data row0 col1\" >12.137982</td>\n",
       "      <td id=\"T_4e11b_row0_col2\" class=\"data row0 col2\" >0.233464</td>\n",
       "      <td id=\"T_4e11b_row0_col3\" class=\"data row0 col3\" >0.016210</td>\n",
       "      <td id=\"T_4e11b_row0_col4\" class=\"data row0 col4\" >0.431468</td>\n",
       "      <td id=\"T_4e11b_row0_col5\" class=\"data row0 col5\" >11.954261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4e11b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_4e11b_row1_col0\" class=\"data row1 col0\" >lab</td>\n",
       "      <td id=\"T_4e11b_row1_col1\" class=\"data row1 col1\" >11.723279</td>\n",
       "      <td id=\"T_4e11b_row1_col2\" class=\"data row1 col2\" >0.253753</td>\n",
       "      <td id=\"T_4e11b_row1_col3\" class=\"data row1 col3\" >0.014002</td>\n",
       "      <td id=\"T_4e11b_row1_col4\" class=\"data row1 col4\" >0.420795</td>\n",
       "      <td id=\"T_4e11b_row1_col5\" class=\"data row1 col5\" >22.111551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4e11b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_4e11b_row2_col0\" class=\"data row2 col0\" >luv</td>\n",
       "      <td id=\"T_4e11b_row2_col1\" class=\"data row2 col1\" >12.149442</td>\n",
       "      <td id=\"T_4e11b_row2_col2\" class=\"data row2 col2\" >0.250899</td>\n",
       "      <td id=\"T_4e11b_row2_col3\" class=\"data row2 col3\" >0.014746</td>\n",
       "      <td id=\"T_4e11b_row2_col4\" class=\"data row2 col4\" >0.416857</td>\n",
       "      <td id=\"T_4e11b_row2_col5\" class=\"data row2 col5\" >20.257921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4e11b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_4e11b_row3_col0\" class=\"data row3 col0\" >pca</td>\n",
       "      <td id=\"T_4e11b_row3_col1\" class=\"data row3 col1\" >11.881371</td>\n",
       "      <td id=\"T_4e11b_row3_col2\" class=\"data row3 col2\" >0.256053</td>\n",
       "      <td id=\"T_4e11b_row3_col3\" class=\"data row3 col3\" >0.014845</td>\n",
       "      <td id=\"T_4e11b_row3_col4\" class=\"data row3 col4\" >0.420383</td>\n",
       "      <td id=\"T_4e11b_row3_col5\" class=\"data row3 col5\" >25.186588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7d6f454d3e50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(result)\n",
    "# save to csv\n",
    "df.to_csv(f\"evaluation/evaluation{group_id}.csv\", index=False)\n",
    "\n",
    "# show table\n",
    "df.style.apply(highlight_best, subset=['Content Loss↓', 'Content Similarity↑','Style Loss↓', 'Style Similarity↑', 'FID↓'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id = \"4\"\n",
    "methods = [\"original\", \"lab\", \"luv\", \"pca\"]\n",
    "data_path = os.path.join('evaluation', 'Stylized', f'style{group_id}_content{group_id}')\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    prepare_eval_images(group_id, methods)\n",
    "\n",
    "result = evaluate_methods(group_id, methods, vgg_extractor)\n",
    "result_all.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5e66d_row0_col4, #T_5e66d_row1_col3, #T_5e66d_row1_col5, #T_5e66d_row2_col1, #T_5e66d_row2_col2 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5e66d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5e66d_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
       "      <th id=\"T_5e66d_level0_col1\" class=\"col_heading level0 col1\" >Content Loss↓</th>\n",
       "      <th id=\"T_5e66d_level0_col2\" class=\"col_heading level0 col2\" >Content Similarity↑</th>\n",
       "      <th id=\"T_5e66d_level0_col3\" class=\"col_heading level0 col3\" >Style Loss↓</th>\n",
       "      <th id=\"T_5e66d_level0_col4\" class=\"col_heading level0 col4\" >Style Similarity↑</th>\n",
       "      <th id=\"T_5e66d_level0_col5\" class=\"col_heading level0 col5\" >FID↓</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5e66d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5e66d_row0_col0\" class=\"data row0 col0\" >original</td>\n",
       "      <td id=\"T_5e66d_row0_col1\" class=\"data row0 col1\" >14.317054</td>\n",
       "      <td id=\"T_5e66d_row0_col2\" class=\"data row0 col2\" >0.257166</td>\n",
       "      <td id=\"T_5e66d_row0_col3\" class=\"data row0 col3\" >0.019180</td>\n",
       "      <td id=\"T_5e66d_row0_col4\" class=\"data row0 col4\" >0.476745</td>\n",
       "      <td id=\"T_5e66d_row0_col5\" class=\"data row0 col5\" >11.471416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e66d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5e66d_row1_col0\" class=\"data row1 col0\" >lab</td>\n",
       "      <td id=\"T_5e66d_row1_col1\" class=\"data row1 col1\" >12.791056</td>\n",
       "      <td id=\"T_5e66d_row1_col2\" class=\"data row1 col2\" >0.273966</td>\n",
       "      <td id=\"T_5e66d_row1_col3\" class=\"data row1 col3\" >0.016723</td>\n",
       "      <td id=\"T_5e66d_row1_col4\" class=\"data row1 col4\" >0.465760</td>\n",
       "      <td id=\"T_5e66d_row1_col5\" class=\"data row1 col5\" >10.104987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e66d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5e66d_row2_col0\" class=\"data row2 col0\" >luv</td>\n",
       "      <td id=\"T_5e66d_row2_col1\" class=\"data row2 col1\" >12.453183</td>\n",
       "      <td id=\"T_5e66d_row2_col2\" class=\"data row2 col2\" >0.282541</td>\n",
       "      <td id=\"T_5e66d_row2_col3\" class=\"data row2 col3\" >0.016747</td>\n",
       "      <td id=\"T_5e66d_row2_col4\" class=\"data row2 col4\" >0.467777</td>\n",
       "      <td id=\"T_5e66d_row2_col5\" class=\"data row2 col5\" >10.311694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e66d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5e66d_row3_col0\" class=\"data row3 col0\" >pca</td>\n",
       "      <td id=\"T_5e66d_row3_col1\" class=\"data row3 col1\" >13.297970</td>\n",
       "      <td id=\"T_5e66d_row3_col2\" class=\"data row3 col2\" >0.272599</td>\n",
       "      <td id=\"T_5e66d_row3_col3\" class=\"data row3 col3\" >0.018034</td>\n",
       "      <td id=\"T_5e66d_row3_col4\" class=\"data row3 col4\" >0.466868</td>\n",
       "      <td id=\"T_5e66d_row3_col5\" class=\"data row3 col5\" >11.758767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7d6f6daef6a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(result)\n",
    "# save to csv\n",
    "df.to_csv(f\"evaluation/evaluation{group_id}.csv\", index=False)\n",
    "\n",
    "# show table\n",
    "df.style.apply(highlight_best, subset=['Content Loss↓', 'Content Similarity↑','Style Loss↓', 'Style Similarity↑', 'FID↓'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id = \"5\"\n",
    "methods = [\"original\", \"lab\", \"luv\", \"pca\"]\n",
    "data_path = os.path.join('evaluation', 'Stylized', f'style{group_id}_content{group_id}')\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    prepare_eval_images(group_id, methods)\n",
    "\n",
    "result = evaluate_methods(group_id, methods, vgg_extractor)\n",
    "result_all.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a9832_row0_col4, #T_a9832_row0_col5, #T_a9832_row1_col1, #T_a9832_row3_col2, #T_a9832_row3_col3 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a9832\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a9832_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
       "      <th id=\"T_a9832_level0_col1\" class=\"col_heading level0 col1\" >Content Loss↓</th>\n",
       "      <th id=\"T_a9832_level0_col2\" class=\"col_heading level0 col2\" >Content Similarity↑</th>\n",
       "      <th id=\"T_a9832_level0_col3\" class=\"col_heading level0 col3\" >Style Loss↓</th>\n",
       "      <th id=\"T_a9832_level0_col4\" class=\"col_heading level0 col4\" >Style Similarity↑</th>\n",
       "      <th id=\"T_a9832_level0_col5\" class=\"col_heading level0 col5\" >FID↓</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a9832_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a9832_row0_col0\" class=\"data row0 col0\" >original</td>\n",
       "      <td id=\"T_a9832_row0_col1\" class=\"data row0 col1\" >17.637327</td>\n",
       "      <td id=\"T_a9832_row0_col2\" class=\"data row0 col2\" >0.236190</td>\n",
       "      <td id=\"T_a9832_row0_col3\" class=\"data row0 col3\" >0.040290</td>\n",
       "      <td id=\"T_a9832_row0_col4\" class=\"data row0 col4\" >0.402300</td>\n",
       "      <td id=\"T_a9832_row0_col5\" class=\"data row0 col5\" >20.605291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9832_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a9832_row1_col0\" class=\"data row1 col0\" >lab</td>\n",
       "      <td id=\"T_a9832_row1_col1\" class=\"data row1 col1\" >16.527629</td>\n",
       "      <td id=\"T_a9832_row1_col2\" class=\"data row1 col2\" >0.246978</td>\n",
       "      <td id=\"T_a9832_row1_col3\" class=\"data row1 col3\" >0.042242</td>\n",
       "      <td id=\"T_a9832_row1_col4\" class=\"data row1 col4\" >0.386422</td>\n",
       "      <td id=\"T_a9832_row1_col5\" class=\"data row1 col5\" >24.583978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9832_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a9832_row2_col0\" class=\"data row2 col0\" >luv</td>\n",
       "      <td id=\"T_a9832_row2_col1\" class=\"data row2 col1\" >16.588091</td>\n",
       "      <td id=\"T_a9832_row2_col2\" class=\"data row2 col2\" >0.254815</td>\n",
       "      <td id=\"T_a9832_row2_col3\" class=\"data row2 col3\" >0.040738</td>\n",
       "      <td id=\"T_a9832_row2_col4\" class=\"data row2 col4\" >0.386453</td>\n",
       "      <td id=\"T_a9832_row2_col5\" class=\"data row2 col5\" >25.350727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9832_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a9832_row3_col0\" class=\"data row3 col0\" >pca</td>\n",
       "      <td id=\"T_a9832_row3_col1\" class=\"data row3 col1\" >16.609615</td>\n",
       "      <td id=\"T_a9832_row3_col2\" class=\"data row3 col2\" >0.260192</td>\n",
       "      <td id=\"T_a9832_row3_col3\" class=\"data row3 col3\" >0.038969</td>\n",
       "      <td id=\"T_a9832_row3_col4\" class=\"data row3 col4\" >0.390851</td>\n",
       "      <td id=\"T_a9832_row3_col5\" class=\"data row3 col5\" >24.487526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7d6f454d3a30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(result)\n",
    "# save to csv\n",
    "df.to_csv(f\"evaluation/evaluation{group_id}.csv\", index=False)\n",
    "\n",
    "# show table\n",
    "df.style.apply(highlight_best, subset=['Content Loss↓', 'Content Similarity↑','Style Loss↓', 'Style Similarity↑', 'FID↓'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e4df9_row0_col4, #T_e4df9_row0_col5, #T_e4df9_row3_col1, #T_e4df9_row3_col2, #T_e4df9_row3_col3 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e4df9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e4df9_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
       "      <th id=\"T_e4df9_level0_col1\" class=\"col_heading level0 col1\" >Content Loss↓</th>\n",
       "      <th id=\"T_e4df9_level0_col2\" class=\"col_heading level0 col2\" >Content Similarity↑</th>\n",
       "      <th id=\"T_e4df9_level0_col3\" class=\"col_heading level0 col3\" >Style Loss↓</th>\n",
       "      <th id=\"T_e4df9_level0_col4\" class=\"col_heading level0 col4\" >Style Similarity↑</th>\n",
       "      <th id=\"T_e4df9_level0_col5\" class=\"col_heading level0 col5\" >FID↓</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e4df9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e4df9_row0_col0\" class=\"data row0 col0\" >original</td>\n",
       "      <td id=\"T_e4df9_row0_col1\" class=\"data row0 col1\" >13.881 ±2.268</td>\n",
       "      <td id=\"T_e4df9_row0_col2\" class=\"data row0 col2\" >0.257 ±0.032</td>\n",
       "      <td id=\"T_e4df9_row0_col3\" class=\"data row0 col3\" >0.022 ±0.012</td>\n",
       "      <td id=\"T_e4df9_row0_col4\" class=\"data row0 col4\" >0.469 ±0.052</td>\n",
       "      <td id=\"T_e4df9_row0_col5\" class=\"data row0 col5\" >12.685 ±5.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4df9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e4df9_row1_col0\" class=\"data row1 col0\" >lab</td>\n",
       "      <td id=\"T_e4df9_row1_col1\" class=\"data row1 col1\" >13.192 ±1.907</td>\n",
       "      <td id=\"T_e4df9_row1_col2\" class=\"data row1 col2\" >0.273 ±0.033</td>\n",
       "      <td id=\"T_e4df9_row1_col3\" class=\"data row1 col3\" >0.025 ±0.014</td>\n",
       "      <td id=\"T_e4df9_row1_col4\" class=\"data row1 col4\" >0.448 ±0.044</td>\n",
       "      <td id=\"T_e4df9_row1_col5\" class=\"data row1 col5\" >20.539 ±8.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4df9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e4df9_row2_col0\" class=\"data row2 col0\" >luv</td>\n",
       "      <td id=\"T_e4df9_row2_col1\" class=\"data row2 col1\" >13.355 ±1.831</td>\n",
       "      <td id=\"T_e4df9_row2_col2\" class=\"data row2 col2\" >0.274 ±0.031</td>\n",
       "      <td id=\"T_e4df9_row2_col3\" class=\"data row2 col3\" >0.024 ±0.013</td>\n",
       "      <td id=\"T_e4df9_row2_col4\" class=\"data row2 col4\" >0.447 ±0.044</td>\n",
       "      <td id=\"T_e4df9_row2_col5\" class=\"data row2 col5\" >19.718 ±6.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4df9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e4df9_row3_col0\" class=\"data row3 col0\" >pca</td>\n",
       "      <td id=\"T_e4df9_row3_col1\" class=\"data row3 col1\" >13.178 ±2.021</td>\n",
       "      <td id=\"T_e4df9_row3_col2\" class=\"data row3 col2\" >0.278 ±0.026</td>\n",
       "      <td id=\"T_e4df9_row3_col3\" class=\"data row3 col3\" >0.021 ±0.011</td>\n",
       "      <td id=\"T_e4df9_row3_col4\" class=\"data row3 col4\" >0.448 ±0.043</td>\n",
       "      <td id=\"T_e4df9_row3_col5\" class=\"data row3 col5\" >19.159 ±5.958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7d6f42bf1cd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten result_all into a single list of dictionaries\n",
    "flat_results = [item for sublist in result_all for item in sublist]\n",
    "\n",
    "# Convert to a DataFrame for easier processing\n",
    "df = pd.DataFrame(flat_results)\n",
    "\n",
    "# Columns to compute mean and standard deviation\n",
    "metrics = ['Content Loss↓', 'Content Similarity↑', 'Style Loss↓', 'Style Similarity↑', 'FID↓']\n",
    "\n",
    "# Initialize a formatted results list\n",
    "formatted_results = []\n",
    "\n",
    "# Group by 'Method' and calculate mean ± std\n",
    "for method, group in df.groupby('Method'):\n",
    "    formatted_row = {'Method': method}\n",
    "    for metric in metrics:\n",
    "        mean = group[metric].mean()\n",
    "        std = group[metric].std()\n",
    "        formatted_row[metric] = f\"{mean:.3f} ±{std:.3f}\"\n",
    "    formatted_results.append(formatted_row)\n",
    "\n",
    "# Create a new DataFrame with formatted results\n",
    "formatted_df = pd.DataFrame(formatted_results)\n",
    "\n",
    "\n",
    "# Sort the DataFrame by 'Method' in the specified order\n",
    "method_order = ['original', 'lab', 'luv', 'pca']\n",
    "formatted_df['Method'] = pd.Categorical(formatted_df['Method'], categories=method_order, ordered=True)\n",
    "formatted_df = formatted_df.sort_values('Method')\n",
    "# Reset the index to reorder it\n",
    "formatted_df = formatted_df.reset_index(drop=True)\n",
    "\n",
    "# Save to CSV if needed\n",
    "formatted_df.to_csv(\"evaluation/evaluation.csv\", index=False)\n",
    "\n",
    "# Print each formatted item\n",
    "formatted_df\n",
    "formatted_df.style.apply(highlight_best, subset=metrics, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run all groups\n",
    "# result_all = []\n",
    "\n",
    "# for id in tqdm(range(1, 6), desc=\"Processing all groups\"):\n",
    "#     group_id = str(id)\n",
    "#     methods = [\"original\", \"lab\", \"luv\", \"pca\"]\n",
    "#     data_path = os.path.join('evaluation', 'Stylized', f'style{group_id}_content{group_id}')\n",
    "\n",
    "#     if not os.path.exists(data_path):\n",
    "#         prepare_eval_images(group_id, methods)\n",
    "\n",
    "#     result = evaluate_methods(group_id, methods, vgg_extractor)\n",
    "#     result_all.append(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bluebottle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
